{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SparkContext as 'sc'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>7</td><td>application_1472684042648_0008</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn0-ichspa.m1z1y2jehioufalia2pydmlvqd.bx.internal.cloudapp.net:8088/proxy/application_1472684042648_0008/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.13:30060/node/containerlogs/container_e02_1472684042648_0008_01_000001/spark\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating HiveContext as 'sqlContext'\n",
      "SparkContext and HiveContext created. Executing user code ...\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an RDD from sample data\n",
    "hvacText = sc.textFile(\"wasb:///HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv\")\n",
    "\n",
    "# Create a schema for our data\n",
    "Entry = Row('Date', 'Time', 'TargetTemp', 'ActualTemp', 'BuildingID')\n",
    "\n",
    "# Parse the data and create a schema\n",
    "hvacParts = hvacText.map(lambda s: s.split(',')).filter(lambda s: s[0] != 'Date')\n",
    "hvac = hvacParts.map(lambda p: Entry(str(p[0]), str(p[1]), int(p[2]), int(p[3]), int(p[6])))\n",
    "\n",
    "hvacTable = sqlContext.createDataFrame(hvac)\n",
    "hvacTable.registerTempTable('hvactemptable')\n",
    "dfw = DataFrameWriter(hvacTable)\n",
    "dfw.saveAsTable('hvac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAVC table is accessable from Hive and PowerBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
