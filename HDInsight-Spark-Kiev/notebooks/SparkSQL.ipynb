{"nbformat_minor": 1, "cells": [{"source": "# Access to Hive Metastore", "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "%%sql\nSHOW TABLES", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nSELECT clientid, count(*) as cnt \nFROM hivesampletable \nWHERE state = 'Washington' AND devicemake = 'Microsoft' AND querydwelltime > 15\nGROUP BY clientid", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Creating SparkContext as 'sc'\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>application_1472684042648_0006</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn0-ichspa.m1z1y2jehioufalia2pydmlvqd.bx.internal.cloudapp.net:8088/proxy/application_1472684042648_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.13:30060/node/containerlogs/container_e02_1472684042648_0006_01_000001/spark\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "Creating HiveContext as 'sqlContext'\nSparkContext and HiveContext created. Executing user code ...\n"}, {"output_type": "stream", "name": "stderr", "text": "Widget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\nWidget Javascript not detected.  It may not be installed properly. Did you enable the widgetsnbextension? If not, then run \"jupyter nbextension enable --py --sys-prefix widgetsnbextension\"\n"}], "metadata": {"collapsed": false}}, {"source": "# Data Frames", "cell_type": "markdown", "metadata": {}}, {"execution_count": 6, "cell_type": "code", "source": "# hivesampletabledf is a dataframe\nhivesampletabledf = sqlContext.table('hivesampletable')", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 5, "cell_type": "code", "source": "hivesampletabledf.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------+---------+------+--------------+----------+-----------+-------------+-------------+--------------+---------+--------------------+\n|clientid|querytime|market|deviceplatform|devicemake|devicemodel|        state|      country|querydwelltime|sessionid|sessionpagevieworder|\n+--------+---------+------+--------------+----------+-----------+-------------+-------------+--------------+---------+--------------------+\n|       8| 18:54:20| en-US|       Android|   Samsung|   SCH-i500|   California|United States|    13.9204007|        0|                   0|\n|      23| 19:19:44| en-US|       Android|       HTC| Incredible| Pennsylvania|United States|          null|        0|                   0|\n|      23| 19:19:46| en-US|       Android|       HTC| Incredible| Pennsylvania|United States|     1.4757422|        0|                   1|\n|      23| 19:19:47| en-US|       Android|       HTC| Incredible| Pennsylvania|United States|      0.245968|        0|                   2|\n|      28| 01:37:50| en-US|       Android|  Motorola|    Droid X|     Colorado|United States|    20.3095339|        1|                   1|\n|      28| 00:53:31| en-US|       Android|  Motorola|    Droid X|     Colorado|United States|    16.2981668|        0|                   0|\n|      28| 00:53:50| en-US|       Android|  Motorola|    Droid X|     Colorado|United States|     1.7715228|        0|                   1|\n|      28| 16:44:21| en-US|       Android|  Motorola|    Droid X|         Utah|United States|    11.6755987|        2|                   1|\n|      28| 16:43:41| en-US|       Android|  Motorola|    Droid X|         Utah|United States|    36.9446892|        2|                   0|\n|      28| 01:37:19| en-US|       Android|  Motorola|    Droid X|     Colorado|United States|    28.9811416|        1|                   0|\n|      30| 17:19:36| en-US|        RIM OS|       RIM|       9650|Massachusetts|United States|   3468.538966|        0|                   2|\n|      30| 17:17:18| en-US|        RIM OS|       RIM|       9650|Massachusetts|United States|    66.8533378|        0|                   1|\n|      30| 17:16:40| en-US|        RIM OS|       RIM|       9650|Massachusetts|United States|          null|        0|                   0|\n|      43| 00:44:46| en-US|        RIM OS|       RIM|       9330|Massachusetts|United States|     2.3198876|        0|                   1|\n|      43| 00:44:41| en-US|        RIM OS|       RIM|       9330|Massachusetts|United States|          null|        0|                   0|\n|      45| 21:24:03| en-US|       Android|   Samsung|   SCH-i500|   California|United States|     1.7547729|        1|                   1|\n|      45| 21:09:43| en-US|       Android|   Samsung|   SCH-i500|     Illinois|United States|   857.1453275|        1|                   0|\n|      45| 20:01:50| en-US|       Android|   Samsung|   SCH-i500|   New Jersey|United States|    12.4195326|        0|                   0|\n|      49| 03:05:50| en-US|       Android|        LG|      VS740|     New York|United States|          null|        0|                   0|\n|      59| 01:23:42| en-US|       Android|        LG|      VS660|       Nevada|United States|     0.4996229|        0|                   0|\n+--------+---------+------+--------------+----------+-----------+-------------+-------------+--------------+---------+--------------------+\nonly showing top 20 rows"}], "metadata": {"collapsed": false}}, {"execution_count": 11, "cell_type": "code", "source": "# Use GroupBy clause with dataframe \nhivesampletabledf.groupBy('deviceplatform').count().select('deviceplatform', 'count').orderBy('count', ascending=False).limit(3).show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------------+-----+\n|deviceplatform|count|\n+--------------+-----+\n|       Android|31591|\n|     iPhone OS|22731|\n|        RIM OS| 3464|\n+--------------+-----+"}], "metadata": {"collapsed": false}}, {"source": "# Data Frames from files", "cell_type": "markdown", "metadata": {}}, {"execution_count": 9, "cell_type": "code", "source": "from pyspark.sql.types import *\nimport csv\nfrom StringIO import StringIO\ndef csv_values_in_line(line):\n    sio = StringIO(line)\n    value = csv.reader(sio).next()\n    sio.close()\n    return value\nbuildings = sc.textFile('wasb:///HdiSamples/HdiSamples/SensorSampleData/building/building.csv')\\\n              .map(csv_values_in_line)\\\n              .filter(lambda r: r[0] != 'BuildingID') \\\n              .map(lambda r: (int(r[0]), r[1], int(r[2]), r[3], r[4]))\nschema = StructType([StructField('BuildingID', IntegerType(), True),\n                     StructField('BuildingMgr', StringType(), True),\n                     StructField('BuildingAge', IntegerType(), True),\n                     StructField('HVACProduct', StringType(), True),\n                     StructField('Country', StringType(), True)])\ndf = sqlContext.createDataFrame(buildings, schema)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 10, "cell_type": "code", "source": "df.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------+-----------+-----------+-----------+------------+\n|BuildingID|BuildingMgr|BuildingAge|HVACProduct|     Country|\n+----------+-----------+-----------+-----------+------------+\n|         1|         M1|         25|     AC1000|         USA|\n|         2|         M2|         27|     FN39TG|      France|\n|         3|         M3|         28|     JDNS77|      Brazil|\n|         4|         M4|         17|     GG1919|     Finland|\n|         5|         M5|          3|    ACMAX22|   Hong Kong|\n|         6|         M6|          9|     AC1000|   Singapore|\n|         7|         M7|         13|     FN39TG|South Africa|\n|         8|         M8|         25|     JDNS77|   Australia|\n|         9|         M9|         11|     GG1919|      Mexico|\n|        10|        M10|         23|    ACMAX22|       China|\n|        11|        M11|         14|     AC1000|     Belgium|\n|        12|        M12|         26|     FN39TG|     Finland|\n|        13|        M13|         25|     JDNS77|Saudi Arabia|\n|        14|        M14|         17|     GG1919|     Germany|\n|        15|        M15|         19|    ACMAX22|      Israel|\n|        16|        M16|         23|     AC1000|      Turkey|\n|        17|        M17|         11|     FN39TG|       Egypt|\n|        18|        M18|         25|     JDNS77|   Indonesia|\n|        19|        M19|         14|     GG1919|      Canada|\n|        20|        M20|         19|    ACMAX22|   Argentina|\n+----------+-----------+-----------+-----------+------------+"}], "metadata": {"collapsed": false}}, {"execution_count": 11, "cell_type": "code", "source": "# Register the dataframe as a temporary table called HVAC\ndf.registerTempTable('HVAC')", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 13, "cell_type": "code", "source": "%%sql\nSELECT * FROM HVAC WHERE BuildingAge >= 20", "outputs": [], "metadata": {"collapsed": true}}, {"source": "# Convert to RDD", "cell_type": "markdown", "metadata": {}}, {"execution_count": 13, "cell_type": "code", "source": "hive_rdd = hivesampletabledf.rdd\nhive_rdd.take(3)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Row(clientid=u'8', querytime=u'18:54:20', market=u'en-US', deviceplatform=u'Android', devicemake=u'Samsung', devicemodel=u'SCH-i500', state=u'California', country=u'United States', querydwelltime=13.9204007, sessionid=0, sessionpagevieworder=0), Row(clientid=u'23', querytime=u'19:19:44', market=u'en-US', deviceplatform=u'Android', devicemake=u'HTC', devicemodel=u'Incredible', state=u'Pennsylvania', country=u'United States', querydwelltime=None, sessionid=0, sessionpagevieworder=0), Row(clientid=u'23', querytime=u'19:19:46', market=u'en-US', deviceplatform=u'Android', devicemake=u'HTC', devicemodel=u'Incredible', state=u'Pennsylvania', country=u'United States', querydwelltime=1.4757422, sessionid=0, sessionpagevieworder=1)]"}], "metadata": {"collapsed": false}}, {"execution_count": 15, "cell_type": "code", "source": "hive_rdd.filter(lambda x: x.deviceplatform == 'Android').count()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "31591"}], "metadata": {"collapsed": false}}, {"execution_count": 16, "cell_type": "code", "source": "hive_rdd.count()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "59793"}], "metadata": {"collapsed": false}}, {"source": "# Create table in Hive from Data Frame", "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "hivesampletablequerydf = sqlContext.sql(\"\"\"\nSELECT clientid, count(*) as cnt \nFROM hivesampletable \nWHERE state = 'Washington' AND devicemake = 'Microsoft' AND querydwelltime > 15\nGROUP BY clientid\n\"\"\")\nhivesampletablequerydf.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------+---+\n|clientid|cnt|\n+--------+---+\n|  109426|  1|\n|    2601|  2|\n|   46780|  1|\n+--------+---+"}], "metadata": {"collapsed": false}}, {"execution_count": 1, "cell_type": "code", "source": "%%sql -q\nCREATE TABLE IF NOT EXISTS hivesampletablecopypy ( \n                    clientid string, \n                    querytime string, \n                    market string, \n                    deviceplatform string,\n                    devicemake string,\n                    devicemodel string,\n                    state string, \n                    country string,\n                    querydwelltime double,\n                    sessionid bigint,\n                    sessionpagevieworder bigint )", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Creating SparkContext as 'sc'\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>6</td><td>application_1472684042648_0007</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn0-ichspa.m1z1y2jehioufalia2pydmlvqd.bx.internal.cloudapp.net:8088/proxy/application_1472684042648_0007/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.12:30060/node/containerlogs/container_e02_1472684042648_0007_01_000001/spark\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "Creating HiveContext as 'sqlContext'\nSparkContext and HiveContext created. Executing user code ...\n"}], "metadata": {"collapsed": false}}, {"execution_count": 7, "cell_type": "code", "source": "from pyspark.sql import DataFrameWriter\n\ndfw = DataFrameWriter(hivesampletabledf)\ndfw.insertInto('hivesampletablecopypy', overwrite=True)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": 8, "cell_type": "code", "source": "%%sql\nSHOW TABLES", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "widgets": {"state": {"fad2e17c2f8b463a859764eefb8049ac": {"views": [{"cell_index": 0}]}, "425756e08bd14d5a8334c3c482ef9eb9": {"views": [{"cell_index": 0}]}, "a3de1858d8e743999235a5a9e0bf920b": {"views": [{"cell_index": 15}]}, "0fc86f51c0374c678a36eb0aebeee0cc": {"views": [{"cell_index": 2}]}, "28044a2314944b80b586a680e42ef71d": {"views": [{"cell_index": 15}]}, "f153d00aa1124920b970112fc1174719": {"views": [{"cell_index": 11}]}, "9d10fcbceeed4b22a7fc0212a4c38bd4": {"views": [{"cell_index": 2}]}, "3ff6787adf164218af67385df50c0811": {"views": [{"cell_index": 11}]}, "073a1b948f3046f6bc69450afc0fb960": {"views": [{"cell_index": 0}]}, "84284cf0edc44238ac97d1f6ea326446": {"views": [{"cell_index": 11}]}, "9c3bf761e49e4b73bba460d8d728184d": {"views": [{"cell_index": 0}]}}, "version": "1.2.0"}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"name": "python"}}}}